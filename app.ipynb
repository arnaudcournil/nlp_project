{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\courn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\courn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from unidecode import unidecode\n",
    "import json\n",
    "import random\n",
    "import ast\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from transformers import pipeline\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Warning Shown\n"
     ]
    }
   ],
   "source": [
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn(\"DelftStack\")\n",
    "warnings.warn(\"Do not show this message\")\n",
    "print(\"No Warning Shown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://fr.trustpilot.com/categories/car_dealer?page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     web_page \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m      9\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(web_page, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1386\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1385\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1386\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1315\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1314\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get all compagny url\n",
    "page = 1\n",
    "result_len = 0\n",
    "compagnies_url = []\n",
    "while True:\n",
    "    url = f\"https://fr.trustpilot.com/categories/car_dealer?page={page}\"\n",
    "    response = requests.get(url)\n",
    "    web_page = response.text\n",
    "    soup = BeautifulSoup(web_page, \"html.parser\")\n",
    "\n",
    "    resp = soup.select(\"a[data-business-unit-card-link]\")\n",
    "    for res in resp:\n",
    "        url = res[\"href\"].replace(\"/review/\", \"\")\n",
    "        compagnies_url.append(url)\n",
    "    if result_len == 0:\n",
    "        result_len = len(resp)\n",
    "    elif result_len != len(resp):\n",
    "        break\n",
    "    print(page)\n",
    "    page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compagny_url(compagny_url):\n",
    "    # Initialize lists\n",
    "    review_titles = []\n",
    "    review_ratings = []\n",
    "    review_texts = []\n",
    "    review_locations = []\n",
    "    page_number = []\n",
    "\n",
    "    # Set Trustpilot page numbers to scrape here\n",
    "    from_page = 1\n",
    "    to_page = 500\n",
    "\n",
    "    for i in range(from_page, to_page + 1):\n",
    "        response = requests.get(f\"https://fr.trustpilot.com/review/{compagny_url}?page={i}\")\n",
    "        web_page = response.text\n",
    "        soup = BeautifulSoup(web_page, \"html.parser\")\n",
    "\n",
    "        if soup.find_all(\"article\") == []:\n",
    "            break\n",
    "\n",
    "        for review in soup.find_all(\"article\"):\n",
    "            # Review titles\n",
    "            review_title = review.select_one(\"a[data-review-title-typography]\")\n",
    "            if review_title == None:\n",
    "                review_titles.append(\"\")\n",
    "            else:\n",
    "                review_titles.append(review_title.getText())\n",
    "\n",
    "            # Review text\n",
    "            review_text = review.select_one(\"p[data-service-review-text-typography]\")\n",
    "            if review_text == None:\n",
    "                review_texts.append(\"\")\n",
    "            else:\n",
    "                review_texts.append(review_text.getText())\n",
    "\n",
    "            # Review ratings\n",
    "            review_rating = review.select_one(\"div[data-service-review-rating]\")\n",
    "            review_ratings.append(review_rating[\"data-service-review-rating\"])\n",
    "                \n",
    "            review_location = review.select_one(\"div[data-consumer-country-typography]\")\n",
    "            if review_location == None:\n",
    "                review_locations.append(\"\")\n",
    "            else:\n",
    "                review_locations.append(review_location.getText())\n",
    "            # Trustpilot page number\n",
    "            page_number.append(i)\n",
    "\n",
    "    # Create final dataframe from lists\n",
    "    return pd.DataFrame(list(zip([compagny_url for i in range(len(review_titles))], review_titles, review_ratings, review_texts, review_locations)),\n",
    "                    columns =['compagny', 'review_title', 'review_rating', 'review_text', 'review_location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [09:13<00:00,  7.01s/it] \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for compagny in tqdm(compagnies_url):\n",
    "    result = compagny_url(compagny)\n",
    "    df = pd.concat([df, result])\n",
    "\n",
    "df.to_csv(\"reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    useless_words = pd.read_csv(\"most_frequent_words_mixed.csv\", header=None)[0].tolist()[:100]\n",
    "except:\n",
    "    useless_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertForSequenceClassification.\n",
      "\n",
      "All the layers of TFCamembertForSequenceClassification were initialized from the model checkpoint at tblard/tf-allocine.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "STEMMER = FrenchStemmer()\n",
    "spell = SpellChecker(language='fr')\n",
    "pipe = pipeline(\"text-classification\", model=\"tblard/tf-allocine\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Suppression des accents\n",
    "    text = unidecode(text)\n",
    "    # Suppression du code HTML\n",
    "    text = re.sub(re.compile(\"<.*?>\"), \"\", text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9/s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Suppresssion des nombres\n",
    "    text = re.sub(r'[0-9]+', ' ', text)\n",
    "    # Supprimer les lignes vides\n",
    "    text = text.split('\\n')\n",
    "    text = [line.strip() for line in text if len(line) > 0]\n",
    "    text = ' '.join(text)\n",
    "    # Supprimer les liens\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    # Lemmatiser les mots\n",
    "    tokens = word_tokenize(text.lower(), language='french')\n",
    "    return tokens\n",
    "\n",
    "n_grams = lambda tokens, n: [\" \".join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "\n",
    "def text2Token(text, spelling = True, stem = True, len_word_min = 2, spell = spell, useless_words = useless_words, use_n_grams = True):\n",
    "    stopword = stopwords.words('french')\n",
    "    word_tokens = preprocess_text(text)\n",
    "    word_tokens = [word for word in word_tokens if word not in stopword and word not in useless_words and len(word) > len_word_min]\n",
    "    if spelling:\n",
    "        word_tokens = [spell.correction(word) for word in word_tokens]\n",
    "        word_tokens = [word for word in word_tokens if word != None]\n",
    "    if stem:\n",
    "        word_tokens = [STEMMER.stem(token) for token in word_tokens]\n",
    "    if use_n_grams:\n",
    "        word_tokens = word_tokens + n_grams(word_tokens, 2) + n_grams(word_tokens, 3)\n",
    "    return word_tokens\n",
    "\n",
    "def getMostFrequentWords(documents, top=10):\n",
    "    # Compter les mots\n",
    "    word_count = {}\n",
    "    for doc in documents:\n",
    "        for word in doc:\n",
    "            if word in word_count:\n",
    "                word_count[word] += 1\n",
    "            else:\n",
    "                word_count[word] = 1\n",
    "\n",
    "    # Trier les mots par fréquence décroissante\n",
    "    word_count = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if top == float('inf'):\n",
    "        return word_count\n",
    "    \n",
    "    return word_count[:top]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess data\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "print(\"Preprocess data\")\n",
    "df = pd.read_csv(\"reviews.csv\")\n",
    "df = df.dropna(subset=['review_text'])\n",
    "df = df[df[\"review_location\"]  == \"FR\"]\n",
    "df = df.drop_duplicates(subset=['review_text'])\n",
    "df = df.reset_index(drop=True)\n",
    "df = df[['review_text', 'review_rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get most frequent words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16933 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/16933 [00:09<2:19:33,  2.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df_prepared_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df))):\n\u001b[1;32m----> 3\u001b[0m     df_prepared_data\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtext2Token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreview_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43museless_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[3], line 31\u001b[0m, in \u001b[0;36mtext2Token\u001b[1;34m(text, spelling, stem, len_word_min, spell, useless_words)\u001b[0m\n\u001b[0;32m     29\u001b[0m word_tokens \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_tokens \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopword \u001b[38;5;129;01mand\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m useless_words \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(word) \u001b[38;5;241m>\u001b[39m len_word_min]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spelling:\n\u001b[1;32m---> 31\u001b[0m     word_tokens \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mspell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword_tokens\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     32\u001b[0m     word_tokens \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_tokens \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stem:\n",
      "Cell \u001b[1;32mIn[3], line 31\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     29\u001b[0m word_tokens \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_tokens \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopword \u001b[38;5;129;01mand\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m useless_words \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(word) \u001b[38;5;241m>\u001b[39m len_word_min]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spelling:\n\u001b[1;32m---> 31\u001b[0m     word_tokens \u001b[38;5;241m=\u001b[39m [\u001b[43mspell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_tokens]\n\u001b[0;32m     32\u001b[0m     word_tokens \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_tokens \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stem:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spellchecker\\spellchecker.py:159\u001b[0m, in \u001b[0;36mSpellChecker.correction\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The most probable correct spelling for the word\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m    word (str): The word to correct\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    str: The most likely candidate or None if no correction is present\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m word \u001b[38;5;241m=\u001b[39m ensure_unicode(word)\n\u001b[1;32m--> 159\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcandidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spellchecker\\spellchecker.py:186\u001b[0m, in \u001b[0;36mSpellChecker.candidates\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# if still not found, use the edit distance 1 to calc edit distance 2\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distance \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 186\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknown(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__edit_distance_alt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tmp:\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tmp\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spellchecker\\spellchecker.py:253\u001b[0m, in \u001b[0;36mSpellChecker.__edit_distance_alt\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m    251\u001b[0m tmp_words \u001b[38;5;241m=\u001b[39m [ensure_unicode(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m    252\u001b[0m tmp \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_case_sensitive \u001b[38;5;28;01melse\u001b[39;00m w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp_words \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_if_should_check(w)]\n\u001b[1;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43me2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknown\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medit_distance_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43me1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spellchecker\\spellchecker.py:253\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m tmp_words \u001b[38;5;241m=\u001b[39m [ensure_unicode(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m    252\u001b[0m tmp \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_case_sensitive \u001b[38;5;28;01melse\u001b[39;00m w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp_words \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_if_should_check(w)]\n\u001b[1;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [e2 \u001b[38;5;28;01mfor\u001b[39;00m e1 \u001b[38;5;129;01min\u001b[39;00m tmp \u001b[38;5;28;01mfor\u001b[39;00m e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknown(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medit_distance_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43me1\u001b[49m\u001b[43m)\u001b[49m)]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spellchecker\\spellchecker.py:228\u001b[0m, in \u001b[0;36mSpellChecker.edit_distance_1\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    226\u001b[0m deletes \u001b[38;5;241m=\u001b[39m [L \u001b[38;5;241m+\u001b[39m R[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m L, R \u001b[38;5;129;01min\u001b[39;00m splits \u001b[38;5;28;01mif\u001b[39;00m R]\n\u001b[0;32m    227\u001b[0m transposes \u001b[38;5;241m=\u001b[39m [L \u001b[38;5;241m+\u001b[39m R[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m R[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m R[\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m L, R \u001b[38;5;129;01min\u001b[39;00m splits \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(R) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 228\u001b[0m replaces \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mletters\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    229\u001b[0m inserts \u001b[38;5;241m=\u001b[39m [L \u001b[38;5;241m+\u001b[39m c \u001b[38;5;241m+\u001b[39m R \u001b[38;5;28;01mfor\u001b[39;00m L, R \u001b[38;5;129;01min\u001b[39;00m splits \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m letters]\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m(deletes \u001b[38;5;241m+\u001b[39m transposes \u001b[38;5;241m+\u001b[39m replaces \u001b[38;5;241m+\u001b[39m inserts)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spellchecker\\spellchecker.py:228\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    226\u001b[0m deletes \u001b[38;5;241m=\u001b[39m [L \u001b[38;5;241m+\u001b[39m R[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m L, R \u001b[38;5;129;01min\u001b[39;00m splits \u001b[38;5;28;01mif\u001b[39;00m R]\n\u001b[0;32m    227\u001b[0m transposes \u001b[38;5;241m=\u001b[39m [L \u001b[38;5;241m+\u001b[39m R[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m R[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m R[\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m L, R \u001b[38;5;129;01min\u001b[39;00m splits \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(R) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 228\u001b[0m replaces \u001b[38;5;241m=\u001b[39m [L \u001b[38;5;241m+\u001b[39m c \u001b[38;5;241m+\u001b[39m R[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m L, R \u001b[38;5;129;01min\u001b[39;00m splits \u001b[38;5;28;01mif\u001b[39;00m R \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m letters]\n\u001b[0;32m    229\u001b[0m inserts \u001b[38;5;241m=\u001b[39m [L \u001b[38;5;241m+\u001b[39m c \u001b[38;5;241m+\u001b[39m R \u001b[38;5;28;01mfor\u001b[39;00m L, R \u001b[38;5;129;01min\u001b[39;00m splits \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m letters]\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m(deletes \u001b[38;5;241m+\u001b[39m transposes \u001b[38;5;241m+\u001b[39m replaces \u001b[38;5;241m+\u001b[39m inserts)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_prepared_data = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    df_prepared_data.append(text2Token(df.at[i, \"review_text\"], stem=False, useless_words=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_words = getMostFrequentWords(df_prepared_data, top=1000)\n",
    "pd.DataFrame(most_frequent_words, columns=[\"word\", \"count\"]).to_csv(\"most_frequent_words.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traslate most frequent words list to english (for better performance of the pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_words = pd.read_csv(\"most_frequent_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"en\" not in most_frequent_words.columns:\n",
    "    most_frequent_words[\"en\"] = [None for i in range(len(most_frequent_words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import translators as ts\n",
    "\n",
    "def translate(word):\n",
    "    try:\n",
    "        return ts.tencent(word, to_language=\"en\", from_language=\"fr\")\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [47:31<00:00,  2.85s/it] \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(most_frequent_words))):\n",
    "    if most_frequent_words.at[i, \"en\"] == None:\n",
    "        most_frequent_words.at[i, \"en\"] = translate(most_frequent_words.at[i, \"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_words.to_csv(\"most_frequent_words.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the sentiment of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_words = pd.read_csv(\"most_frequent_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"sentiment\" in most_frequent_words.columns:\n",
    "    most_frequent_words[\"sentiment\"] = [None for i in range(len(most_frequent_words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:29<00:00,  3.71it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(most_frequent_words))):\n",
    "    if most_frequent_words.at[i, \"sentiment\"] == None and str(most_frequent_words.at[i, \"word\"]) != \"nan\":\n",
    "        pipe_res = pipe(most_frequent_words.at[i, \"word\"])[0]\n",
    "        most_frequent_words.at[i, \"sentiment\"] = pipe_res[\"label\"] if pipe_res[\"score\"] > 0.65 else \"MIXED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_words.to_csv(\"most_frequent_words.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_words[most_frequent_words[\"sentiment\"] == \"MIXED\"][[\"word\"]].to_csv(\"most_frequent_words_mixed.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_words = most_frequent_words[most_frequent_words[\"sentiment\"] == \"MIXED\"][\"word\"].tolist()[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate train dataset\n",
      "Spell check for train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1905 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1905/1905 [17:02<00:00,  1.86it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save train dataset\n",
      "Generate test dataset\n",
      "Save test dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate train tokenized dataset\n",
    "print(\"Generate train tokenized dataset\")\n",
    "train = df.copy()\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X = train[[\"review_text\"]]\n",
    "y = train[\"review_rating\"]\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "train = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "train_idx = train.index.tolist()\n",
    "train = train.reset_index(drop=True)\n",
    "train.to_csv(\"train_untokenized.csv\", index=False)\n",
    "\n",
    "# Spell check for train dataset\n",
    "print(\"Spell check for train dataset\")\n",
    "for i in tqdm(range(len(train))):\n",
    "    train.at[i, \"review_text\"] = json.dumps(text2Token(train.at[i, \"review_text\"]))\n",
    "\n",
    "# Save train dataset\n",
    "print(\"Save train dataset\")\n",
    "train.to_csv(\"reviews_train.csv\", index=False)\n",
    "\n",
    "# Generate test dataset\n",
    "print(\"Generate test dataset\")\n",
    "test = df.copy()\n",
    "test = test.drop(train_idx)\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X = test[[\"review_text\"]]\n",
    "y = test[\"review_rating\"]\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "test = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "# Save test dataset\n",
    "print(\"Save test dataset\")\n",
    "test.to_csv(\"reviews_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_untokenized = pd.read_csv(\"train_untokenized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1990/1990 [11:14<00:00,  2.95it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_pipe_res(text):\n",
    "    try:\n",
    "        return pipe(text)[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "pipe_score = []\n",
    "for i in tqdm(range(len(train_untokenized))):\n",
    "    pipe_score.append(get_pipe_res(train_untokenized.at[i, \"review_text\"]))\n",
    "\n",
    "real_score = train_untokenized[\"review_rating\"].tolist()\n",
    "\n",
    "while None in pipe_score:\n",
    "    idx = pipe_score.index(None)\n",
    "    del real_score[idx]\n",
    "    del pipe_score[idx]\n",
    "\n",
    "pipe_label = [elmt[\"label\"] for elmt in pipe_score]\n",
    "pipe_score = [elmt[\"score\"] for elmt in pipe_score]\n",
    "df_pipe = pd.DataFrame(list(zip(real_score, pipe_label, pipe_score)), columns=[\"real_score\", \"pipe_label\", \"pipe_score\"])\n",
    "df_pipe[\"pipe_label\"] = df_pipe[\"pipe_label\"].apply(lambda x: 1 if x == \"POSITIVE\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 608/608 [04:27<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "pipe_score = []\n",
    "for i in tqdm(range(len(test))):\n",
    "    pipe_score.append(get_pipe_res(test.at[i, \"review_text\"]))\n",
    "\n",
    "real_score = test[\"review_rating\"].tolist()\n",
    "\n",
    "while None in pipe_score:\n",
    "    idx = pipe_score.index(None)\n",
    "    del real_score[idx]\n",
    "    del pipe_score[idx]\n",
    "\n",
    "pipe_label = [elmt[\"label\"] for elmt in pipe_score]\n",
    "pipe_score = [elmt[\"score\"] for elmt in pipe_score]\n",
    "df_pipe_test = pd.DataFrame(list(zip(real_score, pipe_label, pipe_score)), columns=[\"real_score\", \"pipe_label\", \"pipe_score\"])\n",
    "df_pipe_test[\"pipe_label\"] = df_pipe_test[\"pipe_label\"].apply(lambda x: 1 if x == \"POSITIVE\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.9053851431359945\n",
      "MSE: 1.14167469575748\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reg = LinearRegression().fit(df_pipe[[\"pipe_score\", \"pipe_label\"]], df_pipe[\"real_score\"])\n",
    "\n",
    "y_pred = reg.predict(df_pipe_test[[\"pipe_score\", \"pipe_label\"]])\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(df_pipe_test['real_score'], y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(df_pipe_test['real_score'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7337770382695508\n",
      "MSE: 1.276206322795341\n"
     ]
    }
   ],
   "source": [
    "reg = LogisticRegression().fit(df_pipe[[\"pipe_score\", \"pipe_label\"]], df_pipe[\"real_score\"])\n",
    "\n",
    "y_pred = reg.predict(df_pipe_test[[\"pipe_score\", \"pipe_label\"]])\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(df_pipe_test['real_score'], y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(df_pipe_test['real_score'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.8012523209233274\n",
      "MSE: 0.9530500843969638\n"
     ]
    }
   ],
   "source": [
    "reg = SVR().fit(df_pipe[[\"pipe_score\", \"pipe_label\"]], df_pipe[\"real_score\"])\n",
    "\n",
    "y_pred = reg.predict(df_pipe_test[[\"pipe_score\", \"pipe_label\"]])\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(df_pipe_test['real_score'], y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(df_pipe_test['real_score'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7935105391627738\n",
      "MSE: 0.9682374371766631\n"
     ]
    }
   ],
   "source": [
    "reg = XGBRegressor().fit(df_pipe[[\"pipe_score\", \"pipe_label\"]], df_pipe[\"real_score\"])\n",
    "\n",
    "y_pred = reg.predict(df_pipe_test[[\"pipe_score\", \"pipe_label\"]])\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(df_pipe_test['real_score'], y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(df_pipe_test['real_score'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6967306077172966\n",
      "MSE: 0.8983029138491782\n"
     ]
    }
   ],
   "source": [
    "reg = RandomForestRegressor().fit(df_pipe[[\"pipe_score\", \"pipe_label\"]], df_pipe[\"real_score\"])\n",
    "\n",
    "y_pred = reg.predict(df_pipe_test[[\"pipe_score\", \"pipe_label\"]])\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(df_pipe_test['real_score'], y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(df_pipe_test['real_score'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(reg, open(\"pipe_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopDocs(bm25, query, documents, ratings, top=5):\n",
    "    # Calculer les scores de similarité\n",
    "    scores = bm25.get_scores(query)\n",
    "\n",
    "    # Associer chaque avis à son score\n",
    "    doc_scores = list(zip(documents, scores, ratings))\n",
    "\n",
    "    # Trier les avis par score décroissant\n",
    "    return sorted(doc_scores, key=lambda x: x[1], reverse=True)[:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1905/1905 [00:40<00:00, 47.46it/s] \n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"reviews_train.csv\")\n",
    "train[\"review_text\"] = train[\"review_text\"].apply(lambda x: ast.literal_eval(x))\n",
    "documents = train[\"review_text\"].tolist()\n",
    "ratings = train[\"review_rating\"].tolist()\n",
    "bm25 = BM25Okapi(documents)\n",
    "\n",
    "bm25_scores_1, bm25_scores_2, bm25_scores_3, bm25_scores_4, bm25_scores_5 = [], [], [], [], []\n",
    "bm25_ratings_1, bm25_ratings_2, bm25_ratings_3, bm25_ratings_4, bm25_ratings_5 = [], [], [], [], []\n",
    "for i in tqdm(range(len(train))):\n",
    "    top_docs = getTopDocs(bm25, train[\"review_text\"].iloc[i], documents, ratings, top=6)[1:]\n",
    "    bm25_scores_1.append(top_docs[0][1])\n",
    "    bm25_scores_2.append(top_docs[1][1])\n",
    "    bm25_scores_3.append(top_docs[2][1])\n",
    "    bm25_scores_4.append(top_docs[3][1])\n",
    "    bm25_scores_5.append(top_docs[4][1])\n",
    "    bm25_ratings_1.append(top_docs[0][2])\n",
    "    bm25_ratings_2.append(top_docs[1][2])\n",
    "    bm25_ratings_3.append(top_docs[2][2])\n",
    "    bm25_ratings_4.append(top_docs[3][2])\n",
    "    bm25_ratings_5.append(top_docs[4][2])\n",
    "\n",
    "real_score = train[\"review_rating\"].tolist()\n",
    "\n",
    "df_bm25 = pd.DataFrame(list(zip(real_score, bm25_ratings_1, bm25_ratings_2, bm25_ratings_3, bm25_ratings_4, bm25_ratings_5, bm25_scores_1, bm25_scores_2, bm25_scores_3, bm25_scores_4, bm25_scores_5)), columns=[\"real_score\", \"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 608/608 [03:29<00:00,  2.91it/s]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"reviews_test.csv\")\n",
    "\n",
    "bm25_scores_1, bm25_scores_2, bm25_scores_3, bm25_scores_4, bm25_scores_5 = [], [], [], [], []\n",
    "bm25_ratings_1, bm25_ratings_2, bm25_ratings_3, bm25_ratings_4, bm25_ratings_5 = [], [], [], [], []\n",
    "for i in tqdm(range(len(test))):\n",
    "    top_docs = getTopDocs(bm25, text2Token(test[\"review_text\"].iloc[i]), documents, ratings, top=5)\n",
    "    bm25_scores_1.append(top_docs[0][1])\n",
    "    bm25_scores_2.append(top_docs[1][1])\n",
    "    bm25_scores_3.append(top_docs[2][1])\n",
    "    bm25_scores_4.append(top_docs[3][1])\n",
    "    bm25_scores_5.append(top_docs[4][1])\n",
    "    bm25_ratings_1.append(top_docs[0][2])\n",
    "    bm25_ratings_2.append(top_docs[1][2])\n",
    "    bm25_ratings_3.append(top_docs[2][2])\n",
    "    bm25_ratings_4.append(top_docs[3][2])\n",
    "    bm25_ratings_5.append(top_docs[4][2])\n",
    "\n",
    "real_score = test[\"review_rating\"].tolist()\n",
    "\n",
    "df_bm25_test = pd.DataFrame(list(zip(real_score, bm25_ratings_1, bm25_ratings_2, bm25_ratings_3, bm25_ratings_4, bm25_ratings_5, bm25_scores_1, bm25_scores_2, bm25_scores_3, bm25_scores_4, bm25_scores_5)), columns=[\"real_score\", \"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.8897406237777181\n",
      "MSE: 1.2068894929259424\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(df_bm25[[\"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]], df_bm25[\"real_score\"])\n",
    "\n",
    "y_pred = reg.predict(df_bm25_test[[\"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]])\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(df_bm25_test['real_score'], y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(df_bm25_test['real_score'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(reg, open(\"bm25_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.9638157894736842\n",
      "MSE: 1.8651315789473684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\courn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "reg = LogisticRegression().fit(df_bm25[[\"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]], df_bm25[\"real_score\"])\n",
    "\n",
    "y_pred = reg.predict(df_bm25_test[[\"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]])\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(df_bm25_test['real_score'], y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(df_bm25_test['real_score'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.8957257740097123\n",
      "MSE: 1.2168132659887394\n"
     ]
    }
   ],
   "source": [
    "reg = SVR().fit(df_bm25[[\"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]], df_bm25[\"real_score\"])\n",
    "\n",
    "y_pred = reg.predict(df_bm25_test[[\"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]])\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(df_bm25_test['real_score'], y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(df_bm25_test['real_score'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.9585107639431953\n",
      "MSE: 1.3620632070876018\n"
     ]
    }
   ],
   "source": [
    "reg = XGBRegressor().fit(df_bm25[[\"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]], df_bm25[\"real_score\"])\n",
    "\n",
    "y_pred = reg.predict(df_bm25_test[[\"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]])\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(df_bm25_test['real_score'], y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(df_bm25_test['real_score'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.9271417214912281\n",
      "MSE: 1.2284654359009504\n"
     ]
    }
   ],
   "source": [
    "reg = RandomForestRegressor().fit(df_bm25[[\"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]], df_bm25[\"real_score\"])\n",
    "\n",
    "y_pred = reg.predict(df_bm25_test[[\"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]])\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(df_bm25_test['real_score'], y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(df_bm25_test['real_score'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve BM25 + Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopDocs(bm25, query, documents, ratings, top=5):\n",
    "    # Calculer les scores de similarité\n",
    "    scores = bm25.get_scores(query)\n",
    "\n",
    "    # Associer chaque avis à son score\n",
    "    doc_scores = list(zip(documents, scores, ratings))\n",
    "\n",
    "    # Trier les avis par score décroissant\n",
    "    return sorted(doc_scores, key=lambda x: x[1], reverse=True)[:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1990/1990 [00:41<00:00, 47.90it/s] \n"
     ]
    }
   ],
   "source": [
    "train_untokenized = pd.read_csv(\"train_untokenized.csv\")\n",
    "\n",
    "def get_pipe_res(text):\n",
    "    try:\n",
    "        return pipe(text)[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "pipe_score = []\n",
    "for i in tqdm(range(len(train_untokenized))):\n",
    "    pipe_score.append(get_pipe_res(train_untokenized.at[i, \"review_text\"]))\n",
    "\n",
    "real_score = train_untokenized[\"review_rating\"].tolist()\n",
    "\n",
    "review_text_tokenized = []\n",
    "for i in tqdm(range(len(train_untokenized))):\n",
    "    if str(train_untokenized.at[i, \"review_text\"]) == \"nan\":\n",
    "        review_text_tokenized.append([\"None\"])\n",
    "        continue\n",
    "    review_text_tokenized.append(text2Token(train_untokenized.at[i, \"review_text\"]))\n",
    "\n",
    "train_untokenized[\"review_text_tokenized\"] = review_text_tokenized\n",
    "\n",
    "documents = train_untokenized[\"review_text_tokenized\"].tolist()\n",
    "ratings = train_untokenized[\"review_rating\"].tolist()\n",
    "bm25 = BM25Okapi(documents)\n",
    "\n",
    "bm25_scores_1, bm25_scores_2, bm25_scores_3, bm25_scores_4, bm25_scores_5 = [], [], [], [], []\n",
    "bm25_ratings_1, bm25_ratings_2, bm25_ratings_3, bm25_ratings_4, bm25_ratings_5 = [], [], [], [], []\n",
    "for i in tqdm(range(len(train_untokenized))):\n",
    "    top_docs = getTopDocs(bm25, train_untokenized[\"review_text_tokenized\"].iloc[i], documents, ratings, top=6)[1:]\n",
    "    bm25_scores_1.append(top_docs[0][1])\n",
    "    bm25_scores_2.append(top_docs[1][1])\n",
    "    bm25_scores_3.append(top_docs[2][1])\n",
    "    bm25_scores_4.append(top_docs[3][1])\n",
    "    bm25_scores_5.append(top_docs[4][1])\n",
    "    bm25_ratings_1.append(top_docs[0][2])\n",
    "    bm25_ratings_2.append(top_docs[1][2])\n",
    "    bm25_ratings_3.append(top_docs[2][2])\n",
    "    bm25_ratings_4.append(top_docs[3][2])\n",
    "    bm25_ratings_5.append(top_docs[4][2])\n",
    "\n",
    "while None in pipe_score:\n",
    "    idx = pipe_score.index(None)\n",
    "    del real_score[idx]\n",
    "    del pipe_score[idx]\n",
    "    del bm25_scores_1[idx]\n",
    "    del bm25_scores_2[idx]\n",
    "    del bm25_scores_3[idx]\n",
    "    del bm25_scores_4[idx]\n",
    "    del bm25_scores_5[idx]\n",
    "    del bm25_ratings_1[idx]\n",
    "    del bm25_ratings_2[idx]\n",
    "    del bm25_ratings_3[idx]\n",
    "    del bm25_ratings_4[idx]\n",
    "    del bm25_ratings_5[idx]\n",
    "\n",
    "pipe_label = [elmt[\"label\"] for elmt in pipe_score]\n",
    "pipe_score = [elmt[\"score\"] for elmt in pipe_score]\n",
    "df_both = pd.DataFrame(list(zip(real_score, pipe_label, pipe_score, bm25_ratings_1, bm25_ratings_2, bm25_ratings_3, bm25_ratings_4, bm25_ratings_5, bm25_scores_1, bm25_scores_2, bm25_scores_3, bm25_scores_4, bm25_scores_5)), columns=[\"real_score\", \"pipe_label\", \"pipe_score\", \"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"])\n",
    "df_both[\"pipe_label\"] = df_both[\"pipe_label\"].apply(lambda x: 1 if x == \"POSITIVE\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 608/608 [02:34<00:00,  3.95it/s]\n",
      "100%|██████████| 608/608 [03:20<00:00,  3.03it/s]\n",
      "100%|██████████| 608/608 [00:11<00:00, 50.84it/s] \n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"reviews_test.csv\")\n",
    "\n",
    "pipe_score = []\n",
    "for i in tqdm(range(len(test))):\n",
    "    pipe_score.append(get_pipe_res(test.at[i, \"review_text\"]))\n",
    "\n",
    "real_score = test[\"review_rating\"].tolist()\n",
    "\n",
    "review_text_tokenized = []\n",
    "for i in tqdm(range(len(test))):\n",
    "    if str(test.at[i, \"review_text\"]) == \"nan\":\n",
    "        review_text_tokenized.append([\"None\"])\n",
    "        continue\n",
    "    review_text_tokenized.append(text2Token(test.at[i, \"review_text\"]))\n",
    "\n",
    "test[\"review_text_tokenized\"] = review_text_tokenized\n",
    "\n",
    "bm25_scores_1, bm25_scores_2, bm25_scores_3, bm25_scores_4, bm25_scores_5 = [], [], [], [], []\n",
    "bm25_ratings_1, bm25_ratings_2, bm25_ratings_3, bm25_ratings_4, bm25_ratings_5 = [], [], [], [], []\n",
    "\n",
    "for i in tqdm(range(len(test))):\n",
    "    top_docs = getTopDocs(bm25, test[\"review_text_tokenized\"].iloc[i], documents, ratings, top=5)\n",
    "    bm25_scores_1.append(top_docs[0][1])\n",
    "    bm25_scores_2.append(top_docs[1][1])\n",
    "    bm25_scores_3.append(top_docs[2][1])\n",
    "    bm25_scores_4.append(top_docs[3][1])\n",
    "    bm25_scores_5.append(top_docs[4][1])\n",
    "    bm25_ratings_1.append(top_docs[0][2])\n",
    "    bm25_ratings_2.append(top_docs[1][2])\n",
    "    bm25_ratings_3.append(top_docs[2][2])\n",
    "    bm25_ratings_4.append(top_docs[3][2])\n",
    "    bm25_ratings_5.append(top_docs[4][2])\n",
    "\n",
    "while None in pipe_score:\n",
    "    idx = pipe_score.index(None)\n",
    "    del real_score[idx]\n",
    "    del pipe_score[idx]\n",
    "    del bm25_scores_1[idx]\n",
    "    del bm25_scores_2[idx]\n",
    "    del bm25_scores_3[idx]\n",
    "    del bm25_scores_4[idx]\n",
    "    del bm25_scores_5[idx]\n",
    "    del bm25_ratings_1[idx]\n",
    "    del bm25_ratings_2[idx]\n",
    "    del bm25_ratings_3[idx]\n",
    "    del bm25_ratings_4[idx]\n",
    "    del bm25_ratings_5[idx]\n",
    "\n",
    "pipe_label = [elmt[\"label\"] for elmt in pipe_score]\n",
    "pipe_score = [elmt[\"score\"] for elmt in pipe_score]\n",
    "df_both_test = pd.DataFrame(list(zip(real_score, pipe_label, pipe_score, bm25_ratings_1, bm25_ratings_2, bm25_ratings_3, bm25_ratings_4, bm25_ratings_5, bm25_scores_1, bm25_scores_2, bm25_scores_3, bm25_scores_4, bm25_scores_5)), columns=[\"real_score\", \"pipe_label\", \"pipe_score\", \"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"])\n",
    "df_both_test[\"pipe_label\"] = df_both_test[\"pipe_label\"].apply(lambda x: 1 if x == \"POSITIVE\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.760856239534132\n",
      "MSE: 0.8547959146309988\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(df_both[[\"pipe_score\", \"pipe_label\", \"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]], df_both[\"real_score\"])\n",
    "\n",
    "y_pred = reg.predict(df_both_test[[\"pipe_score\", \"pipe_label\", \"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]])\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(df_both_test['real_score'], y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(df_both_test['real_score'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7271214642262895\n",
      "MSE: 1.259567387687188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\courn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "reg = LogisticRegression().fit(df_both[[\"pipe_score\", \"pipe_label\", \"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]], df_both[\"real_score\"])\n",
    "\n",
    "y_pred = reg.predict(df_both_test[[\"pipe_score\", \"pipe_label\", \"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]])\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(df_both_test['real_score'], y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(df_both_test['real_score'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.911549568336651\n",
      "MSE: 1.1600571423842934\n"
     ]
    }
   ],
   "source": [
    "reg = SVR().fit(df_both[[\"pipe_score\", \"pipe_label\", \"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]], df_both[\"real_score\"])\n",
    "\n",
    "y_pred = reg.predict(df_both_test[[\"pipe_score\", \"pipe_label\", \"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]])\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(df_both_test['real_score'], y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(df_both_test['real_score'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7354411515538982\n",
      "MSE: 0.8689947146491467\n"
     ]
    }
   ],
   "source": [
    "reg = XGBRegressor().fit(df_both[[\"pipe_score\", \"pipe_label\", \"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]], df_both[\"real_score\"])\n",
    "\n",
    "y_pred = reg.predict(df_both_test[[\"pipe_score\", \"pipe_label\", \"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]])\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(df_both_test['real_score'], y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(df_both_test['real_score'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7139434276206322\n",
      "MSE: 0.7661128119800333\n"
     ]
    }
   ],
   "source": [
    "reg = RandomForestRegressor().fit(df_both[[\"pipe_score\", \"pipe_label\", \"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]], df_both[\"real_score\"])\n",
    "\n",
    "y_pred = reg.predict(df_both_test[[\"pipe_score\", \"pipe_label\", \"bm25_ratings_1\", \"bm25_ratings_2\", \"bm25_ratings_3\", \"bm25_ratings_4\", \"bm25_ratings_5\", \"bm25_scores_1\", \"bm25_scores_2\", \"bm25_scores_3\", \"bm25_scores_4\", \"bm25_scores_5\"]])\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(df_both_test['real_score'], y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(df_both_test['real_score'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(reg, open(\"both_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"reviews_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"review_text\"] = train[\"review_text\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_rating\n",
       "1    381\n",
       "2    381\n",
       "3    381\n",
       "4    381\n",
       "5    381\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"review_rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste d'avis\n",
    "documents = train[\"review_text\"].tolist()\n",
    "\n",
    "# Listes de scores\n",
    "ratings = train[\"review_rating\"].tolist()\n",
    "\n",
    "# Créer un modèle BM25\n",
    "bm25 = BM25Okapi(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopDocs(bm25, query, documents, ratings, top=5):\n",
    "    # Calculer les scores de similarité\n",
    "    scores = bm25.get_scores(query)\n",
    "\n",
    "    # Associer chaque avis à son score\n",
    "    doc_scores = list(zip(documents, scores, ratings))\n",
    "\n",
    "    # Trier les avis par score décroissant\n",
    "    return sorted(doc_scores, key=lambda x: x[1], reverse=True)[:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Not used\n",
    "# Obtenir les mots positifs et négatifs en utilisant bert\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "def getSentiment(text):\n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer.encode(text, return_tensors='pt')\n",
    "    # Reduce the tokens size to 512\n",
    "    tokens = tokens[:, :512]\n",
    "    # Get the prediction\n",
    "    result = model(tokens)\n",
    "    # Return the label\n",
    "    return torch.argmax(result.logits).item()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Not used\n",
    "def getRevelantWords(most_freq, pos_nb = 5, neg_nb = 5):\n",
    "    pos_words = []\n",
    "    neg_words = []\n",
    "    for word, nb in most_freq:\n",
    "        if type(word) == tuple:\n",
    "            word = \" \".join(word)\n",
    "        if getSentiment(word) == 0 and len(neg_words) < neg_nb:\n",
    "            neg_words.append(word)\n",
    "        elif getSentiment(word) == 4 and len(pos_words) < pos_nb:\n",
    "            pos_words.append(word)\n",
    "\n",
    "        if len(neg_words) == neg_nb and len(pos_words) == pos_nb:\n",
    "            break\n",
    "\n",
    "    return pos_words, neg_words\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separer_phrase(phrase):\n",
    "    # On ajoute des points aux sauts de ligne\n",
    "    phrase = phrase.replace('\\n', '.')\n",
    "\n",
    "    # Divise d'abord la phrase en utilisant les points, points d'interrogation, points d'exclamation.\n",
    "    pattern = r'(?<=[.!?])(?=\\s|[A-Z\"\\'(])'\n",
    "    groupes = re.split(pattern, phrase)\n",
    "\n",
    "    groupes_fins = []\n",
    "    for groupe in groupes:\n",
    "        # Combinaison des motifs de virgule et \"et\" en une seule expression régulière\n",
    "        # Sépare sur les virgules (en évitant les nombres décimaux), sur les ; et : et sur les conjonctions de coordinations (avec un contexte spécifique)\n",
    "        pattern_combined = r'(?<=.{20},)\\s(?!\\d)|[;:]|\\b(mais|ou|et|donc|or|ni|car)\\b(?=.{15,})'\n",
    "        sous_groupes = re.split(pattern_combined, groupe)\n",
    "        groupes_fins.extend(sous_groupes)\n",
    "\n",
    "    return [groupe.strip() for groupe in groupes_fins if groupe is not None and groupe.strip() and len(groupe.strip()) > 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOTH_MODEL = pickle.load(open(\"both_model.pkl\", \"rb\"))\n",
    "PIPE_MODEL = pickle.load(open(\"pipe_model.pkl\", \"rb\"))\n",
    "BM25_MODEL = pickle.load(open(\"bm25_model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_score(top_docs, origin_query = None, use_bm25 = True, FIABILITY_THRESHOLD = 0.6):\n",
    "    # Calculer la note moyenne des avis\n",
    "    if use_bm25 and origin_query is None:\n",
    "        return BM25_MODEL.predict(np.array([top_docs[i][2] for i in range(len(top_docs))] + [top_docs[i][1] for i in range(len(top_docs))]).reshape(1, -1))\n",
    "    elif not use_bm25:\n",
    "        pipe_res = pipe(origin_query)[0]\n",
    "        return PIPE_MODEL.predict(np.array([pipe_res[\"score\"], 1 if pipe_res[\"label\"] == \"POSITIVE\" else 0]).reshape(1, -1))\n",
    "    else:\n",
    "            pipe_res = pipe(origin_query)[0]\n",
    "            pipe_score = pipe_res[\"score\"]\n",
    "            pipe_label = 1 if pipe_res[\"label\"] == \"POSITIVE\" else 0\n",
    "            bm25_ratings = [top_docs[i][2] for i in range(len(top_docs))]\n",
    "            bm25_scores = [top_docs[i][1] for i in range(len(top_docs))]\n",
    "            return BOTH_MODEL.predict(np.array([pipe_score, pipe_label] + bm25_ratings + bm25_scores).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRevelantSentences(origin_query, most_freq, documents, ratings, top=5, use_bm25 = True, use_pipe = True):\n",
    "\n",
    "    # Appel de la fonction\n",
    "    groupes = separer_phrase(origin_query)\n",
    "\n",
    "    # Obtenir les scores de chaque groupe\n",
    "    scores = []\n",
    "    for groupe in groupes:\n",
    "        if use_pipe and use_bm25:\n",
    "            scores.append(estimate_score(getTopDocs(bm25, text2Token(groupe), documents, ratings), origin_query))\n",
    "        elif use_pipe:\n",
    "            scores.append(estimate_score(None, origin_query, use_bm25=False))\n",
    "        elif use_bm25:\n",
    "            scores.append(estimate_score(getTopDocs(bm25, text2Token(groupe), documents, ratings)))\n",
    "            \n",
    "    pos_list = []\n",
    "    neg_list = []\n",
    "    for groupe, score in zip(groupes, scores):\n",
    "        group_tokens = text2Token(groupe)\n",
    "        sumFreq = sum([freq for word, freq in most_freq if word in group_tokens])\n",
    "        if score is None:\n",
    "            continue\n",
    "        if score >= 3.5:\n",
    "            pos_list.append((groupe, sumFreq))\n",
    "        elif score <= 2.5:\n",
    "            neg_list.append((groupe, sumFreq))\n",
    "\n",
    "    pos_list = [sentence[0] for sentence in sorted(pos_list, key=lambda x: x[1], reverse=True)[:top]]\n",
    "    neg_list = [sentence[0] for sentence in sorted(neg_list, key=lambda x: x[1], reverse=True)[:top]]\n",
    "\n",
    "    return pos_list, neg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(origin_query, bm25=bm25, documents=documents, ratings=ratings, spell=spell, use_bm25 = True, use_pipe = True):\n",
    "    query = text2Token(origin_query)\n",
    "    top_docs = []\n",
    "    most_freq = []\n",
    "    if use_bm25:\n",
    "        top_docs = getTopDocs(bm25, query, documents, ratings, top=5)\n",
    "        most_freq = getMostFrequentWords([doc[0] for doc in top_docs], top=50)\n",
    "    pos_list, neg_list = getRevelantSentences(origin_query, most_freq, documents, ratings, top=5, use_bm25 = True, use_pipe = True)\n",
    "    if not use_pipe:\n",
    "        origin_query = None\n",
    "    return estimate_score(top_docs, origin_query, use_bm25=use_bm25), pos_list, neg_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use data unsed and balanced the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_rating\n",
       "1    152\n",
       "3    152\n",
       "4    152\n",
       "5    152\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"reviews_test.csv\")\n",
    "\n",
    "test[\"review_rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Super conseil rapidité de reprise de mon véhicule et rapidité a avoir un véhicule neuf nous conseillons fortement Aramis\n",
      "Vrai score: 3\n",
      "Score: 3.5598636505876087\n",
      "Séquences positives: ['Super conseil rapidité de reprise de mon véhicule', 'rapidité a avoir un véhicule neuf nous conseillons fortement Aramis']\n",
      "Séquences négatives: []\n"
     ]
    }
   ],
   "source": [
    "elmt = test.iloc[random.randint(0, len(test))]\n",
    "origin_query = elmt[\"review_text\"]\n",
    "score, pos_list, neg_list = main(origin_query, use_bm25=True, use_pipe=False)\n",
    "\n",
    "print(f\"Query: {origin_query}\")\n",
    "print(f\"Vrai score: {elmt['review_rating']}\")\n",
    "\n",
    "print(f\"Score: {score[0]}\")\n",
    "print(f\"Séquences positives: {pos_list}\")\n",
    "print(f\"Séquences négatives: {neg_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the average error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 608/608 [05:54<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.8651315789473685\n",
      "MSE: 1.2861842105263157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For bm25\n",
    "ratings_val = []\n",
    "exception_idx = []\n",
    "for i in tqdm(range(len(test))):\n",
    "    try:\n",
    "        elmt = test.iloc[i]\n",
    "        origin_query = elmt[\"review_text\"]\n",
    "        score = estimate_score(getTopDocs(bm25, text2Token(origin_query), documents, ratings))\n",
    "        ratings_val.append(round(score[0]))\n",
    "    except:\n",
    "        exception_idx.append(i)\n",
    "        continue\n",
    "\n",
    "test_sucess = test.drop(exception_idx)\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(test_sucess['review_rating'], ratings_val)}\")\n",
    "print(f\"MSE: {mean_squared_error(test_sucess['review_rating'], ratings_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 608/608 [03:58<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6788685524126455\n",
      "MSE: 1.021630615640599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For pipe\n",
    "ratings_val = []\n",
    "exception_idx = []\n",
    "for i in tqdm(range(len(test))):\n",
    "    try:\n",
    "        elmt = test.iloc[i]\n",
    "        origin_query = elmt[\"review_text\"]\n",
    "        score = estimate_score(None, origin_query, use_bm25=False)\n",
    "        ratings_val.append(round(score[0]))\n",
    "    except:\n",
    "        exception_idx.append(i)\n",
    "        continue\n",
    "\n",
    "test_sucess = test.drop(exception_idx)\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(test_sucess['review_rating'], ratings_val)}\")\n",
    "print(f\"MSE: {mean_squared_error(test_sucess['review_rating'], ratings_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 608/608 [10:01<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6821963394342762\n",
      "MSE: 0.8685524126455907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For bm25 + pipe\n",
    "ratings_val = []\n",
    "exception_idx = []\n",
    "for i in tqdm(range(len(test))):\n",
    "    try:\n",
    "        elmt = test.iloc[i]\n",
    "        origin_query = elmt[\"review_text\"]\n",
    "        score = estimate_score(getTopDocs(bm25, text2Token(origin_query), documents, ratings), origin_query)\n",
    "        ratings_val.append(round(score[0]))\n",
    "    except:\n",
    "        exception_idx.append(i)\n",
    "        continue\n",
    "\n",
    "test_sucess = test.drop(exception_idx)\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(test_sucess['review_rating'], ratings_val)}\")\n",
    "print(f\"MSE: {mean_squared_error(test_sucess['review_rating'], ratings_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequents_vectors = pd.read_csv(\"wordsmost_frequent_with_vectors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequents_vectors[\"embedding\"] = frequents_vectors[\"embedding\"].apply(lambda x: ast.literal_eval(re.sub(r',+', ',', x.replace(\" \", \",\").replace(\"\\n\", \",\")).replace(\"[,\", \"[\").replace(\",]\", \"]\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distances = lambda x, y: sum([abs(x[i] - y[i]) for i in range(len(x))])**1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vector(text):\n",
    "    all_vectors = [frequents_vectors[frequents_vectors[\"fr\"] == word].iloc[0][\"embedding\"] for word in text2Token(text, stem=False, use_n_grams=False) if word in frequents_vectors[\"fr\"].tolist()]\n",
    "    return [sum([vector[i] for vector in all_vectors])/len(all_vectors) for i in range(len(all_vectors[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: 11.621313425\n",
      "Topic 2: 8.125361499999999\n"
     ]
    }
   ],
   "source": [
    "topic1 = \"probleme\"\n",
    "topic2 = \"super qualité\"\n",
    "\n",
    "topic1_vector = text2vector(topic1)\n",
    "topic2_vector = text2vector(topic2)\n",
    "\n",
    "text = \"produit de bonne qualité, je recommande\"\n",
    "text_vector = text2vector(text)\n",
    "\n",
    "print(f\"Topic 1: {euclidean_distances(topic1_vector, text_vector)}\")\n",
    "print(f\"Topic 2: {euclidean_distances(topic2_vector, text_vector)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: 9.328016499999999\n",
      "Topic 2: 12.449311075\n"
     ]
    }
   ],
   "source": [
    "text2 = \"panne\"\n",
    "text2_vector = text2vector(text2)\n",
    "\n",
    "print(f\"Topic 1: {euclidean_distances(topic1_vector, text2_vector)}\")\n",
    "print(f\"Topic 2: {euclidean_distances(topic2_vector, text2_vector)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
